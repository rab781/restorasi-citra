{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d3a544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.7.1+cu118\n",
      "Uninstalling torch-2.7.1+cu118:\n",
      "  Successfully uninstalled torch-2.7.1+cu118\n",
      "Found existing installation: torchvision 0.22.1+cu118\n",
      "Uninstalling torchvision-0.22.1+cu118:\n",
      "  Successfully uninstalled torchvision-0.22.1+cu118\n",
      "Found existing installation: torchaudio 2.7.1+cu118\n",
      "Uninstalling torchaudio-2.7.1+cu118:\n",
      "  Successfully uninstalled torchaudio-2.7.1+cu118\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in d:\\new folder\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\new folder\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\new folder\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\new folder\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\new folder\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\new folder\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in d:\\new folder\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in d:\\new folder\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\new folder\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\new folder\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\new folder\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-win_amd64.whl (2817.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-win_amd64.whl (5.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   ---------------------------------------- 3/3 [torchaudio]\n",
      "\n",
      "Successfully installed torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in d:\\new folder\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\new folder\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\new folder\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\new folder\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\new folder\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\new folder\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in d:\\new folder\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in d:\\new folder\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\new folder\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\new folder\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\new folder\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-win_amd64.whl (2817.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-win_amd64.whl (5.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   ---------------------------------------- 3/3 [torchaudio]\n",
      "\n",
      "Successfully installed torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (d:\\New folder\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (d:\\New folder\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (d:\\New folder\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# UNINSTALL PyTorch versi CPU terlebih dahulu\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# INSTALL PyTorch versi CUDA 11.8\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70a2d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in d:\\new folder\\lib\\site-packages (1.8.2)\n",
      "Requirement already satisfied: pyqubo in d:\\new folder\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: dwave-neal in d:\\new folder\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in d:\\new folder\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in d:\\new folder\\lib\\site-packages (from torchmetrics) (24.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in d:\\new folder\\lib\\site-packages (from torchmetrics) (2.7.1+cu118)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in d:\\new folder\\lib\\site-packages (from torchmetrics) (0.15.2)\n",
      "Requirement already satisfied: dimod<0.13,>=0.9.14 in d:\\new folder\\lib\\site-packages (from pyqubo) (0.12.21)\n",
      "Requirement already satisfied: Deprecated>=1.2.12 in d:\\new folder\\lib\\site-packages (from pyqubo) (1.2.18)\n",
      "Requirement already satisfied: six>=1.15.0 in d:\\new folder\\lib\\site-packages (from pyqubo) (1.16.0)\n",
      "Requirement already satisfied: dwave-samplers<2.0.0,>=1.0.0 in d:\\new folder\\lib\\site-packages (from dwave-neal) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\new folder\\lib\\site-packages (from dwave-samplers<2.0.0,>=1.0.0->dwave-neal) (3.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\new folder\\lib\\site-packages (from Deprecated>=1.2.12->pyqubo) (1.14.1)\n",
      "Requirement already satisfied: setuptools in d:\\new folder\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
      "Requirement already satisfied: typing_extensions in d:\\new folder\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
      "Requirement already satisfied: filelock in d:\\new folder\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\new folder\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in d:\\new folder\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\new folder\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\new folder\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\new folder\\lib\\site-packages (from jinja2->torch>=2.0.0->torchmetrics) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (d:\\New folder\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (d:\\New folder\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (d:\\New folder\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics pyqubo dwave-neal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0961d968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DIAGNOSIS LENGKAP GPU/CUDA\n",
      "============================================================\n",
      "\n",
      "1. Python Version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "\n",
      "2. PyTorch Version: 2.7.1+cu118\n",
      "\n",
      "3. PyTorch compiled with CUDA: True\n",
      "   CUDA built version: 11.8\n",
      "\n",
      "4. Jumlah GPU terdeteksi: 1\n",
      "\n",
      "5.  GPU TERDETEKSI!\n",
      "   - Nama GPU: NVIDIA GeForce RTX 3080\n",
      "   - CUDA Capability: (8, 6)\n",
      "   - Total Memory: 10.00 GB\n",
      "   - Current Device: 0\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cek instalasi CUDA dan PyTorch secara detail\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DIAGNOSIS LENGKAP GPU/CUDA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Cek versi Python\n",
    "print(f\"\\n1. Python Version: {sys.version}\")\n",
    "\n",
    "# 2. Cek versi PyTorch\n",
    "print(f\"\\n2. PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# 3. Cek apakah PyTorch di-compile dengan CUDA\n",
    "print(f\"\\n3. PyTorch compiled with CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"   CUDA built version: {torch.version.cuda if torch.version.cuda else 'TIDAK ADA - PyTorch versi CPU!'}\")\n",
    "\n",
    "# 4. Cek jumlah GPU\n",
    "print(f\"\\n4. Jumlah GPU terdeteksi: {torch.cuda.device_count()}\")\n",
    "\n",
    "# 5. Jika CUDA tersedia, tampilkan info detail\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n5.  GPU TERDETEKSI!\")\n",
    "    print(f\"   - Nama GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   - CUDA Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"   - Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"   - Current Device: {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(f\"\\n5.  GPU TIDAK TERDETEKSI!\")\n",
    "    print(f\"\\n   KEMUNGKINAN PENYEBAB:\")\n",
    "    print(f\"    Driver NVIDIA belum terinstall atau versi lama\")\n",
    "    print(f\"    CUDA Toolkit tidak terinstall\")\n",
    "    print(f\"    PyTorch terinstall versi CPU (bukan CUDA)\")\n",
    "    print(f\"    GPU tidak kompatibel dengan versi CUDA\")\n",
    "    \n",
    "    print(f\"\\n   SOLUSI:\")\n",
    "    print(f\"   1. Cek GPU Anda: Apakah NVIDIA GPU?\")\n",
    "    print(f\"   2. Install/Update Driver NVIDIA terbaru dari:\")\n",
    "    print(f\"      https://www.nvidia.com/Download/index.aspx\")\n",
    "    print(f\"   3. Setelah install driver, restart komputer\")\n",
    "    print(f\"   4. Jalankan sel ini lagi untuk verifikasi\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c622d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CUDA tersedia! Menggunakan GPU: NVIDIA GeForce RTX 3080\n",
      " Jumlah GPU: 1\n",
      " CUDA Version: 11.8\n",
      " Memory GPU: 10.00 GB\n",
      "\n",
      " Device aktif: cuda\n",
      " Semua fungsi dan metrics siap digunakan!\n",
      "\n",
      " Device aktif: cuda\n",
      " Semua fungsi dan metrics siap digunakan!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyqubo import Binary, Array, Constraint, solve_qubo\n",
    "from neal import SimulatedAnnealingSampler\n",
    "\n",
    "# Check CUDA availability and set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\" CUDA tersedia! Menggunakan GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\" Jumlah GPU: {torch.cuda.device_count()}\")\n",
    "    print(f\" CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\" Memory GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\" CUDA tidak tersedia. Menggunakan CPU.\")\n",
    "    print(\" Untuk menggunakan GPU, install PyTorch dengan CUDA:\")\n",
    "    print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "\n",
    "# Initialize metrics from torchmetrics\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "psnr = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, dataloader, device=device):\n",
    "    \"\"\"\n",
    "    Evaluate model with PSNR and SSIM metrics\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        dataloader: DataLoader for evaluation data\n",
    "        device: Device to run evaluation on (cuda/cpu)\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss, avg_psnr, avg_ssim: Average metrics across dataset\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    loss_func = torch.nn.L1Loss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss_val = loss_func(outputs, targets)\n",
    "            psnr_val = psnr(outputs, targets)\n",
    "            ssim_val = ssim(outputs, targets)\n",
    "            total_loss += loss_val.item()\n",
    "            total_psnr += psnr_val.item()\n",
    "            total_ssim += ssim_val.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_psnr = total_psnr / len(dataloader)\n",
    "    avg_ssim = total_ssim / len(dataloader)\n",
    "\n",
    "    return avg_loss, avg_psnr, avg_ssim\n",
    "\n",
    "print(f\"\\n Device aktif: {device}\")\n",
    "print(\" Semua fungsi dan metrics siap digunakan!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8e71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition from halfunet-training.ipynb\n",
    "FILTER = 128\n",
    "\n",
    "class LayerNormFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, weight, bias, eps):\n",
    "        ctx.eps = eps\n",
    "        N, C, H, W = x.size()\n",
    "        mu = x.mean(1, keepdim=True)\n",
    "        var = (x - mu).pow(2).mean(1, keepdim=True)\n",
    "        y = (x - mu) / (var + eps).sqrt()\n",
    "        ctx.save_for_backward(y, var, weight)\n",
    "        y = weight.view(1, C, 1, 1) * y + bias.view(1, C, 1, 1)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = ctx.eps\n",
    "        N, C, H, W = grad_output.size()\n",
    "        y, var, weight = ctx.saved_tensors\n",
    "        g = grad_output * weight.view(1, C, 1, 1)\n",
    "        mean_g = g.mean(dim=1, keepdim=True)\n",
    "        mean_gy = (g * y).mean(dim=1, keepdim=True)\n",
    "        gx = 1. / torch.sqrt(var + eps) * (g - y * mean_gy - mean_g)\n",
    "        return gx, (grad_output * y).sum(dim=3).sum(dim=2).sum(dim=0), grad_output.sum(dim=3).sum(dim=2).sum(\n",
    "            dim=0), None\n",
    "\n",
    "class LayerNorm2d(nn.Module):\n",
    "    def __init__(self, channels, eps=1e-6):\n",
    "        super(LayerNorm2d, self).__init__()\n",
    "        self.register_parameter('weight', nn.Parameter(torch.ones(channels)))\n",
    "        self.register_parameter('bias', nn.Parameter(torch.zeros(channels)))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return LayerNormFunction.apply(x, self.weight, self.bias, self.eps)\n",
    "\n",
    "class SimpleGate(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        return x1 * x2\n",
    "\n",
    "class NAFBlock(nn.Module):\n",
    "    def __init__(self, c, DW_Expand=2, FFN_Expand=2, drop_out_rate=0.):\n",
    "        super().__init__()\n",
    "        dw_channel = c * DW_Expand\n",
    "        self.conv1 = nn.Conv2d(in_channels=c, out_channels=dw_channel, kernel_size=1, padding=0, stride=1, groups=1,\n",
    "                               bias=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels=dw_channel, out_channels=dw_channel, kernel_size=3, padding=1, stride=1,\n",
    "                               groups=dw_channel, bias=True)\n",
    "        self.conv3 = nn.Conv2d(in_channels=dw_channel // 2, out_channels=c, kernel_size=1, padding=0, stride=1,\n",
    "                               groups=1, bias=True)\n",
    "        self.sca = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels=dw_channel // 2, out_channels=dw_channel // 2, kernel_size=1, padding=0, stride=1,\n",
    "                      groups=1, bias=True),\n",
    "        )\n",
    "        self.sg = SimpleGate()\n",
    "        ffn_channel = FFN_Expand * c\n",
    "        self.conv4 = nn.Conv2d(in_channels=c, out_channels=ffn_channel, kernel_size=1, padding=0, stride=1, groups=1,\n",
    "                               bias=True)\n",
    "        self.conv5 = nn.Conv2d(in_channels=ffn_channel // 2, out_channels=c, kernel_size=1, padding=0, stride=1,\n",
    "                               groups=1, bias=True)\n",
    "        self.norm1 = LayerNorm2d(c)\n",
    "        self.norm2 = LayerNorm2d(c)\n",
    "        self.dropout1 = nn.Dropout(drop_out_rate) if drop_out_rate > 0. else nn.Identity()\n",
    "        self.dropout2 = nn.Dropout(drop_out_rate) if drop_out_rate > 0. else nn.Identity()\n",
    "        self.beta = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)\n",
    "        self.gamma = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = inp\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sg(x)\n",
    "        x = x * self.sca(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout1(x)\n",
    "        y = inp + x * self.beta\n",
    "        x = self.conv4(self.norm2(y))\n",
    "        x = self.sg(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.dropout2(x)\n",
    "        return y + x * self.gamma\n",
    "\n",
    "class HalfUNet(nn.Module):\n",
    "    def __init__(self, input_channels=3):\n",
    "        super(HalfUNet, self).__init__()\n",
    "        self.initial = nn.Conv2d(3, FILTER, 1, 1)\n",
    "        self.conv1 = nn.Sequential(NAFBlock(FILTER), NAFBlock(FILTER))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Sequential(NAFBlock(FILTER), NAFBlock(FILTER))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Sequential(NAFBlock(FILTER), NAFBlock(FILTER))\n",
    "        self.conv_up3 = nn.Conv2d(FILTER, FILTER * 16, 1, bias=False)\n",
    "        self.up3 = nn.PixelShuffle(4)\n",
    "        self.conv_up2 = nn.Conv2d(FILTER, FILTER * 4, 1, bias=False)\n",
    "        self.up2 = nn.PixelShuffle(2)\n",
    "        self.final_conv = nn.Conv2d(FILTER, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x1 = self.conv1(x)\n",
    "        pool1 = self.pool1(x1)\n",
    "        x2 = self.conv2(pool1)\n",
    "        pool2 = self.pool2(x2)\n",
    "        x3 = self.conv3(pool2)\n",
    "        up3 = self.conv_up3(x3)\n",
    "        up3 = self.up3(up3)\n",
    "        up2 = self.conv_up2(x2)\n",
    "        up2 = self.up2(up2)\n",
    "        up_scaled = x1 + up2 + up3\n",
    "        output = self.final_conv(up_scaled)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d22f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found 160 noisy images\n",
      " Found 160 ground truth images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e3bbfef0af4699b13b13afe894758d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading and Cropping Images:   0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DataLoaders created (num_workers=0 untuk Windows stability)\n"
     ]
    }
   ],
   "source": [
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, noisy_images_path, gt_images_path, crop_size=256):\n",
    "        self.noisy_paths = noisy_images_path\n",
    "        self.gt_paths = gt_images_path\n",
    "        self.crop_size = crop_size\n",
    "        \n",
    "        self.noisy_patches = []\n",
    "        self.gt_patches = []\n",
    "\n",
    "        # Pre-crop all images into patches during initialization\n",
    "        for idx in tqdm(range(len(self.noisy_paths)), desc=\"Loading and Cropping Images\"):\n",
    "            noisy_img = cv2.cvtColor(cv2.imread(self.noisy_paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "            gt_img = cv2.cvtColor(cv2.imread(self.gt_paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            h, w, _ = noisy_img.shape\n",
    "            \n",
    "            # Create overlapping patches for more data\n",
    "            for i in range(0, h - self.crop_size + 1, self.crop_size // 2):\n",
    "                for j in range(0, w - self.crop_size + 1, self.crop_size // 2):\n",
    "                    noisy_patch = noisy_img[i:i+self.crop_size, j:j+self.crop_size]\n",
    "                    gt_patch = gt_img[i:i+self.crop_size, j:j+self.crop_size]\n",
    "                    \n",
    "                    self.noisy_patches.append(noisy_patch)\n",
    "                    self.gt_patches.append(gt_patch)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        noisy_patch = self.noisy_patches[idx]\n",
    "        gt_patch = self.gt_patches[idx]\n",
    "        \n",
    "        noisy_patch = torch.from_numpy(noisy_patch).permute(2, 0, 1).float() / 255.0\n",
    "        gt_patch = torch.from_numpy(gt_patch).permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "        return noisy_patch, gt_patch\n",
    "\n",
    "# Load data paths\n",
    "DATA_PATH = 'Data/'\n",
    "with open('Scene_Instances.txt') as f:\n",
    "    instances = f.read().splitlines()\n",
    "\n",
    "noisy_images_path = []\n",
    "gt_images_path = []\n",
    "\n",
    "for f in instances:\n",
    "    if not f: continue\n",
    "    p = os.path.join(DATA_PATH, f)\n",
    "    try:\n",
    "        # Find PNG files with GT and NOISY in their names\n",
    "        all_files = os.listdir(p)\n",
    "        gt_files = sorted([os.path.join(p, g) for g in all_files if 'GT' in g and g.endswith('.PNG')])\n",
    "        noisy_files = sorted([os.path.join(p, g) for g in all_files if 'NOISY' in g and g.endswith('.PNG')])\n",
    "        gt_images_path.extend(gt_files)\n",
    "        noisy_images_path.extend(noisy_files)\n",
    "    except OSError as e:\n",
    "        print(f\"Error accessing directory {p}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\" Found {len(noisy_images_path)} noisy images\")\n",
    "print(f\" Found {len(gt_images_path)} ground truth images\")\n",
    "\n",
    "denoising_dataset = DenoisingDataset(noisy_images_path=noisy_images_path, gt_images_path=gt_images_path)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(denoising_dataset))\n",
    "valid_size = int(0.1 * len(denoising_dataset))\n",
    "test_size = len(denoising_dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = random_split(denoising_dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "# Create DataLoaders (num_workers=0 untuk Windows agar tidak freeze)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f\"\\n DataLoaders created (num_workers=0 untuk Windows stability)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ba8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(model, train_loader, valid_loader, epochs, device):\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs for fine-tuning.\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4) # Reduced LR for fine-tuning\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    loss_func = torch.nn.L1Loss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_psnr = 0.0\n",
    "        total_ssim = 0.0\n",
    "\n",
    "        loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for batch_idx, (inputs, targets) in loop:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, targets)\n",
    "            psnr_val = psnr(outputs, targets)\n",
    "            ssim_val = ssim(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_psnr += psnr_val.item()\n",
    "            total_ssim += ssim_val.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loop.set_description(f'Step [{batch_idx+1}/{len(train_loader)}]')\n",
    "            loop.set_postfix(loss=loss.item(), psnr=psnr_val.item(), ssim=ssim_val.item())\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_psnr = total_psnr / len(train_loader)\n",
    "        avg_ssim = total_ssim / len(train_loader)\n",
    "\n",
    "        print(f\"\\nAvg Loss: {avg_loss:.4f}, Avg PSNR: {avg_psnr:.4f}, Avg SSIM: {avg_ssim:.4f}\")\n",
    "\n",
    "        avg_loss_val, avg_psnr_val, avg_ssim_val = evaluate_model(model, valid_loader, device)\n",
    "        print(f\"Val Loss: {avg_loss_val:.4f}, Val PSNR: {avg_psnr_val:.4f}, Val SSIM: {avg_ssim_val:.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Remove DataParallel wrapper if present\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model = model.module\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca3936b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/halfunet/pytorch/default/1/naf_128_double.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m HalfUNet() \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the state dictionary\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m pretrained_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(PRETRAINED_MODEL_PATH, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# The model was likely saved with DataParallel, so we handle the 'module.' prefix\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pretrained_weights, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(k\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule.\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m pretrained_weights\u001b[38;5;241m.\u001b[39mkeys()):\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/halfunet/pytorch/default/1/naf_128_double.pth'"
     ]
    }
   ],
   "source": [
    "PRETRAINED_MODEL_PATH = '/kaggle/input/halfunet/pytorch/default/1/naf_128_double.pth'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Instantiate the correct model architecture\n",
    "model = HalfUNet() \n",
    "\n",
    "# Load the state dictionary\n",
    "pretrained_weights = torch.load(PRETRAINED_MODEL_PATH, map_location=device)\n",
    "\n",
    "# The model was likely saved with DataParallel, so we handle the 'module.' prefix\n",
    "if isinstance(pretrained_weights, dict) and any(k.startswith('module.') for k in pretrained_weights.keys()):\n",
    "    new_state_dict = {k.replace('module.', ''): v for k, v in pretrained_weights.items()}\n",
    "    model.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    model.load_state_dict(pretrained_weights)\n",
    "\n",
    "model.to(device)\n",
    "print(\"Pre-trained model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99702636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INISIALISASI MODEL HALFUNET\n",
      "======================================================================\n",
      "\n",
      " Model HalfUNet berhasil dibuat!\n",
      " Device: cuda\n",
      " Total parameters: 1,042,051\n",
      " Trainable parameters: 1,042,051\n",
      " Model size: 3.98 MB\n",
      "\n",
      "======================================================================\n",
      " MODEL SIAP UNTUK TRAINING!\n",
      "======================================================================\n",
      "\n",
      " Model HalfUNet berhasil dibuat!\n",
      " Device: cuda\n",
      " Total parameters: 1,042,051\n",
      " Trainable parameters: 1,042,051\n",
      " Model size: 3.98 MB\n",
      "\n",
      "======================================================================\n",
      " MODEL SIAP UNTUK TRAINING!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# INISIALISASI MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"INISIALISASI MODEL HALFUNET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Buat model baru\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HalfUNet()\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"\\n Model HalfUNet berhasil dibuat!\")\n",
    "print(f\" Device: {device}\")\n",
    "print(f\" Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\" Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Hitung ukuran model dalam MB\n",
    "model_size = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 * 1024)\n",
    "print(f\" Model size: {model_size:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" MODEL SIAP UNTUK TRAINING!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55725258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MEMINDAHKAN MODEL KE CPU\n",
      "======================================================================\n",
      "\n",
      " Model dipindahkan ke CPU\n",
      " Device sekarang: cpu\n",
      " Training akan lebih lambat di CPU, tapi tidak akan lag komputer\n",
      " Estimasi waktu: ~5-7 menit untuk 50 patches  3 epochs\n",
      "\n",
      "======================================================================\n",
      " MODEL SIAP UNTUK TRAINING DI CPU!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PINDAHKAN MODEL KE CPU (untuk menghindari lag saat training)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MEMINDAHKAN MODEL KE CPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Pindahkan model dari GPU ke CPU\n",
    "cpu_device = torch.device('cpu')\n",
    "model = model.to(cpu_device)\n",
    "\n",
    "print(f\"\\n Model dipindahkan ke CPU\")\n",
    "print(f\" Device sekarang: {cpu_device}\")\n",
    "print(f\" Training akan lebih lambat di CPU, tapi tidak akan lag komputer\")\n",
    "print(f\" Estimasi waktu: ~5-7 menit untuk 50 patches  3 epochs\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" MODEL SIAP UNTUK TRAINING DI CPU!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cfe5fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PILIH STRATEGI TRAINING:\n",
      "======================================================================\n",
      "\n",
      "1. STRATEGI AMAN (Recommended): 10 epoch dulu untuk test\n",
      "2. STRATEGI FULL: 50 epoch langsung\n",
      "3. STRATEGI CEPAT: Subset kecil data untuk quick test\n",
      "\n",
      "Uncomment salah satu opsi di bawah:\n",
      "\n",
      "======================================================================\n",
      "MEMULAI TRAINING - 10 EPOCHS\n",
      "======================================================================\n",
      "\n",
      "Konfigurasi Training:\n",
      "  - Learning Rate: 0.0001\n",
      "  - Max Epochs: 10\n",
      "  - Early Stopping Patience: 5 epochs\n",
      "  - Optimizer: Adam\n",
      "  - Loss Function: L1Loss (MAE)\n",
      "  - Device: cpu\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/10\n",
      "======================================================================\n",
      "\n",
      "Konfigurasi Training:\n",
      "  - Learning Rate: 0.0001\n",
      "  - Max Epochs: 10\n",
      "  - Early Stopping Patience: 5 epochs\n",
      "  - Optimizer: Adam\n",
      "  - Loss Function: L1Loss (MAE)\n",
      "  - Device: cpu\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/10\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a44045b72d40018978b675b2644e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 265\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUncomment salah satu opsi di bawah:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# OPSI 1: STRATEGI AMAN - Test 10 epoch dulu  RECOMMENDED untuk training serius\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Estimasi waktu: 3-5 jam dengan RTX 3080 (tergantung jumlah data)\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m trained_model, history \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[0;32m    266\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    267\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m    268\u001b[0m     valid_loader\u001b[38;5;241m=\u001b[39mvalid_loader,\n\u001b[0;32m    269\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,        \u001b[38;5;66;03m# Coba 10 epoch dulu\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,\n\u001b[0;32m    271\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,       \u001b[38;5;66;03m# Early stop jika 5 epoch tidak ada improvement\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     device\u001b[38;5;241m=\u001b[39mcpu_device  \u001b[38;5;66;03m# PAKSA GUNAKAN CPU untuk menghindari lag\u001b[39;00m\n\u001b[0;32m    273\u001b[0m )\n",
      "Cell \u001b[1;32mIn[13], line 68\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, valid_loader, epochs, lr, device, patience, min_delta)\u001b[0m\n\u001b[0;32m     65\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     69\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, targets)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Check for NaN/Inf\u001b[39;00m\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 104\u001b[0m, in \u001b[0;36mHalfUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    103\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial(x)\n\u001b[1;32m--> 104\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m    105\u001b[0m     pool1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x1)\n\u001b[0;32m    106\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(pool1)\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 74\u001b[0m, in \u001b[0;36mNAFBlock.forward\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     72\u001b[0m x \u001b[38;5;241m=\u001b[39m inp\n\u001b[0;32m     73\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n\u001b[1;32m---> 74\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m     75\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[0;32m     76\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msg(x)\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAINING MODEL DENGAN SAFEGUARDS\n",
    "# ============================================================================\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, epochs=50, lr=1e-4, device=None, \n",
    "                patience=10, min_delta=1e-4):\n",
    "    \"\"\"\n",
    "    Training function dengan monitoring lengkap dan early stopping\n",
    "    \n",
    "    Args:\n",
    "        patience: Berapa epoch menunggu sebelum early stop jika tidak ada improvement\n",
    "        min_delta: Minimum perubahan loss yang dianggap sebagai improvement\n",
    "    \"\"\"\n",
    "    # Set default device jika tidak diberikan\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"MEMULAI TRAINING - {epochs} EPOCHS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Setup optimizer dan scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5\n",
    "    )\n",
    "    loss_func = torch.nn.L1Loss()\n",
    "    \n",
    "    # Untuk tracking best model\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_weights = None\n",
    "    best_epoch = 0\n",
    "    \n",
    "    # Early stopping\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # History untuk plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_psnrs = []\n",
    "    val_psnrs = []\n",
    "    \n",
    "    print(f\"\\nKonfigurasi Training:\")\n",
    "    print(f\"  - Learning Rate: {lr}\")\n",
    "    print(f\"  - Max Epochs: {epochs}\")\n",
    "    print(f\"  - Early Stopping Patience: {patience} epochs\")\n",
    "    print(f\"  - Optimizer: Adam\")\n",
    "    print(f\"  - Loss Function: L1Loss (MAE)\")\n",
    "    print(f\"  - Device: {device}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\"EPOCH {epoch+1}/{epochs}\")\n",
    "        print('=' * 70)\n",
    "        \n",
    "        # ============ TRAINING PHASE ============\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_psnr = 0.0\n",
    "        total_ssim = 0.0\n",
    "        \n",
    "        loop = tqdm(train_loader, desc=f\"Training\")\n",
    "        for batch_idx, (inputs, targets) in enumerate(loop):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, targets)\n",
    "            \n",
    "            # Check for NaN/Inf\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(\"\\n ERROR: Loss is NaN/Inf! Training stopped.\")\n",
    "                print(\"Model terbaik tetap tersimpan.\")\n",
    "                return model, {\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_losses': val_losses,\n",
    "                    'train_psnrs': train_psnrs,\n",
    "                    'val_psnrs': val_psnrs,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                    'stopped_early': True,\n",
    "                    'reason': 'NaN/Inf loss'\n",
    "                }\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping untuk stabilitas\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            with torch.no_grad():\n",
    "                psnr_val = psnr(outputs, targets)\n",
    "                ssim_val = ssim(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_psnr += psnr_val.item()\n",
    "            total_ssim += ssim_val.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            loop.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'psnr': f'{psnr_val.item():.2f}',\n",
    "                'ssim': f'{ssim_val.item():.4f}'\n",
    "            })\n",
    "        \n",
    "        # Calculate average training metrics\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        avg_train_psnr = total_psnr / len(train_loader)\n",
    "        avg_train_ssim = total_ssim / len(train_loader)\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_psnrs.append(avg_train_psnr)\n",
    "        \n",
    "        print(f\"\\n Training Metrics:\")\n",
    "        print(f\"   Loss: {avg_train_loss:.6f} | PSNR: {avg_train_psnr:.2f} dB | SSIM: {avg_train_ssim:.4f}\")\n",
    "        \n",
    "        # ============ VALIDATION PHASE ============\n",
    "        avg_val_loss, avg_val_psnr, avg_val_ssim = evaluate_model(model, valid_loader, device)\n",
    "        \n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_psnrs.append(avg_val_psnr)\n",
    "        \n",
    "        print(f\" Validation Metrics:\")\n",
    "        print(f\"   Loss: {avg_val_loss:.6f} | PSNR: {avg_val_psnr:.2f} dB | SSIM: {avg_val_ssim:.4f}\")\n",
    "        \n",
    "        # Calculate improvement\n",
    "        improvement = best_val_loss - avg_val_loss\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(avg_val_loss)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Tampilkan jika learning rate berubah\n",
    "        if old_lr != new_lr:\n",
    "            print(f\" Learning Rate reduced: {old_lr:.6f}  {new_lr:.6f}\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if improvement > min_delta:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = epoch + 1\n",
    "            patience_counter = 0\n",
    "            \n",
    "            print(f\"  NEW BEST MODEL! (Val Loss improved by {improvement:.6f})\")\n",
    "            \n",
    "            # Save checkpoint (hanya best model, bukan setiap epoch)\n",
    "            checkpoint_path = 'best_model.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'val_psnr': avg_val_psnr,\n",
    "                'val_ssim': avg_val_ssim,\n",
    "            }, checkpoint_path)\n",
    "            print(f\" Checkpoint saved: {checkpoint_path} (epoch {epoch+1})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\" No improvement for {patience_counter}/{patience} epochs\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\n EARLY STOPPING!\")\n",
    "                print(f\"   Validation loss tidak membaik selama {patience} epochs\")\n",
    "                print(f\"   Best model dari epoch {best_epoch} akan digunakan\")\n",
    "                break\n",
    "        \n",
    "        # Deteksi overfitting\n",
    "        if len(train_losses) > 1:\n",
    "            overfitting_ratio = (avg_train_loss / avg_val_loss) if avg_val_loss > 0 else 1\n",
    "            if overfitting_ratio < 0.5:\n",
    "                print(f\" WARNING: Possible overfitting detected!\")\n",
    "                print(f\"   Train/Val loss ratio: {overfitting_ratio:.3f}\")\n",
    "                print(f\"   Consider stopping training atau mengurangi complexity\")\n",
    "        \n",
    "        # Monitor GPU memory (hanya jika training di GPU)\n",
    "        if torch.cuda.is_available() and device.type == 'cuda':\n",
    "            memory_allocated = torch.cuda.memory_allocated(device) / (1024**3)\n",
    "            memory_reserved = torch.cuda.memory_reserved(device) / (1024**3)\n",
    "            print(f\" GPU Memory: Allocated={memory_allocated:.2f}GB, Reserved={memory_reserved:.2f}GB\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" TRAINING SELESAI!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load best model weights\n",
    "    if best_model_weights is not None:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "        print(f\" Best model loaded from epoch {best_epoch} (Val Loss: {best_val_loss:.6f})\")\n",
    "    else:\n",
    "        print(\" No improvement was made. Keeping initial model.\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(train_losses, val_losses, train_psnrs, val_psnrs)\n",
    "    \n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_psnrs': train_psnrs,\n",
    "        'val_psnrs': val_psnrs,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'best_epoch': best_epoch,\n",
    "        'stopped_early': patience_counter >= patience\n",
    "    }\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_psnrs, val_psnrs):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot Loss\n",
    "    ax1.plot(train_losses, label='Train Loss', marker='o', linewidth=2)\n",
    "    ax1.plot(val_losses, label='Val Loss', marker='s', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Tambahkan best point\n",
    "    best_idx = val_losses.index(min(val_losses))\n",
    "    ax1.plot(best_idx, val_losses[best_idx], 'r*', markersize=20, \n",
    "             label=f'Best (Epoch {best_idx+1})')\n",
    "    ax1.legend(fontsize=11)\n",
    "    \n",
    "    # Plot PSNR\n",
    "    ax2.plot(train_psnrs, label='Train PSNR', marker='o', linewidth=2)\n",
    "    ax2.plot(val_psnrs, label='Val PSNR', marker='s', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('PSNR (dB)', fontsize=12)\n",
    "    ax2.set_title('Training and Validation PSNR', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Tambahkan best point\n",
    "    best_psnr_idx = val_psnrs.index(max(val_psnrs))\n",
    "    ax2.plot(best_psnr_idx, val_psnrs[best_psnr_idx], 'r*', markersize=20,\n",
    "             label=f'Best (Epoch {best_psnr_idx+1})')\n",
    "    ax2.legend(fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\" Training history saved: training_history.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# PILIH STRATEGI TRAINING\n",
    "# ============================================================================\n",
    "cpu_device = torch.device('cpu')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PILIH STRATEGI TRAINING:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. STRATEGI AMAN (Recommended): 10 epoch dulu untuk test\")\n",
    "print(\"2. STRATEGI FULL: 50 epoch langsung\")\n",
    "print(\"3. STRATEGI CEPAT: Subset kecil data untuk quick test\")\n",
    "print(\"\\nUncomment salah satu opsi di bawah:\\n\")\n",
    "\n",
    "# OPSI 1: STRATEGI AMAN - Test 10 epoch dulu  RECOMMENDED untuk training serius\n",
    "# Estimasi waktu: 3-5 jam dengan RTX 3080 (tergantung jumlah data)\n",
    "trained_model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    epochs=10,        # Coba 10 epoch dulu\n",
    "    lr=1e-4,\n",
    "    patience=5,       # Early stop jika 5 epoch tidak ada improvement\n",
    "    device=cpu_device  # PAKSA GUNAKAN CPU untuk menghindari lag\n",
    ")\n",
    "\n",
    "# OPSI 2: STRATEGI FULL - Langsung 50 epoch (jika sudah yakin)\n",
    "# Estimasi waktu: 15-24 jam dengan RTX 3080 (untuk dataset penuh)\n",
    "# HANYA untuk training final setelah hyperparameter tuning!\n",
    "# trained_model, history = train_model(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     valid_loader=valid_loader,\n",
    "#     epochs=50,\n",
    "#     lr=1e-4,\n",
    "#     patience=10,\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# OPSI 3: STRATEGI CEPAT - Test dengan subset kecil (paling cepat)\n",
    "# print(\" Membuat subset SANGAT kecil untuk quick test...\")\n",
    "# print(f\" Total train patches: {len(train_dataset)}\")\n",
    "# print(f\" Total valid patches: {len(valid_dataset)}\")\n",
    "\n",
    "# # Ambil hanya 50 patches untuk training CPU (lebih kecil karena CPU lebih lambat)\n",
    "# quick_train_size = min(50, len(train_dataset))\n",
    "# quick_valid_size = min(25, len(valid_dataset))\n",
    "\n",
    "# small_train = Subset(train_dataset, range(0, quick_train_size))\n",
    "# small_valid = Subset(valid_dataset, range(0, quick_valid_size))\n",
    "\n",
    "# print(f\" Quick train size: {len(small_train)} patches\")\n",
    "# print(f\" Quick valid size: {len(small_valid)} patches\")\n",
    "\n",
    "# # Batch size lebih kecil untuk CPU (4 atau 8)\n",
    "# small_train_loader = DataLoader(small_train, batch_size=4, shuffle=True, \n",
    "#                                 num_workers=0, pin_memory=False)  # pin_memory=False untuk CPU\n",
    "# small_valid_loader = DataLoader(small_valid, batch_size=4, shuffle=False,\n",
    "#                                 num_workers=0, pin_memory=False)\n",
    "\n",
    "# print(f\" Train batches per epoch: {len(small_train_loader)}\")\n",
    "# print(f\" Valid batches per epoch: {len(small_valid_loader)}\")\n",
    "\n",
    "# # FORCE CPU MODE - Tidak peduli GPU tersedia atau tidak\n",
    "# cpu_device = torch.device('cpu')\n",
    "# print(f\"\\n  MENGGUNAKAN CPU MODE (untuk menghindari lag)\")\n",
    "# print(f\"  Estimasi: ~5-7 menit untuk 3 epochs di CPU\")\n",
    "# print(\" DataLoader siap, memulai training...\\n\")\n",
    "\n",
    "# trained_model, history = train_model(\n",
    "#     model=model,\n",
    "#     train_loader=small_train_loader,\n",
    "#     valid_loader=small_valid_loader,  # PENTING: Gunakan subset kecil untuk validasi!\n",
    "#     epochs=3,  # Kurangi jadi 3 epoch saja untuk quick test\n",
    "#     lr=1e-4,\n",
    "#     patience=5,  # Tingkatkan patience (tidak akan early stop di 3 epoch)\n",
    "#     device=cpu_device  # PAKSA GUNAKAN CPU!\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5f5fe",
   "metadata": {},
   "source": [
    "##  LOAD CHECKPOINT (OPSIONAL)\n",
    "\n",
    "Jika ingin melanjutkan training dari checkpoint yang tersimpan:\n",
    "\n",
    "```python\n",
    "# Load checkpoint untuk melanjutkan training\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\" Model loaded from epoch {checkpoint['epoch']}\")\n",
    "print(f\" Val Loss: {checkpoint['val_loss']:.6f}\")\n",
    "print(f\" Val PSNR: {checkpoint['val_psnr']:.2f} dB\")\n",
    "\n",
    "# Lalu jalankan train_model() lagi dengan model yang sudah di-load\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c5cc9",
   "metadata": {},
   "source": [
    "##  TIPS OPTIMASI KECEPATAN\n",
    "\n",
    "**Saat ini menggunakan CPU MODE** (untuk menghindari lag komputer)\n",
    "\n",
    "**Perbandingan Kecepatan:**\n",
    "- **CPU Mode**: ~5-7 menit untuk 50 patches  3 epochs (tidak lag komputer)\n",
    "- **GPU Mode**: ~2-3 menit untuk 100 patches  3 epochs (bisa lag komputer)\n",
    "\n",
    "**Jika training CPU terlalu lambat:**\n",
    "\n",
    "1. **Kurangi jumlah data training:**\n",
    "   - Quick test CPU: 25-50 patches (5-7 menit)\n",
    "   - Medium test CPU: 200-500 patches (30-60 menit)\n",
    "   - Full training CPU: **TIDAK DISARANKAN** (bisa 48+ jam!)\n",
    "\n",
    "2. **Batch size untuk CPU:**\n",
    "   - CPU optimal: batch_size=2 atau 4 (jangan terlalu besar)\n",
    "   - Lebih besar tidak selalu lebih cepat di CPU\n",
    "\n",
    "3. **Kurangi jumlah epochs:**\n",
    "   - Quick test: 3 epochs\n",
    "   - Proper training: 5-10 epochs (untuk CPU)\n",
    "\n",
    "4. **Jika ingin kembali ke GPU:**\n",
    "   - Ubah `device=cpu_device` menjadi `device=device` di training cell\n",
    "   - Tingkatkan `quick_train_size` ke 100-200\n",
    "   - Tingkatkan `batch_size` ke 16-32\n",
    "\n",
    "**File checkpoint yang disimpan:**\n",
    "- `best_model.pth` - Model terbaik (diupdate setiap kali ada improvement)\n",
    "- Tidak menyimpan per epoch untuk menghemat ruang disk\n",
    "\n",
    "** Rekomendasi:**\n",
    "- CPU: Untuk quick test dan debugging (tidak lag)\n",
    "- GPU: Untuk training serius (cepat tapi mungkin lag komputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6430cfe",
   "metadata": {},
   "source": [
    "##  SWITCH ANTARA CPU DAN GPU\n",
    "\n",
    "**Jika ingin kembali menggunakan GPU** (setelah CPU mode):\n",
    "\n",
    "```python\n",
    "# Cek apakah GPU tersedia\n",
    "if torch.cuda.is_available():\n",
    "    gpu_device = torch.device('cuda')\n",
    "    model = model.to(gpu_device)\n",
    "    print(f\" Model dipindahkan ke GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Lalu ubah parameter device di train_model():\n",
    "    # device=gpu_device (bukan device=cpu_device)\n",
    "else:\n",
    "    print(\" GPU tidak tersedia\")\n",
    "```\n",
    "\n",
    "**Tips untuk mengurangi lag saat GPU mode:**\n",
    "1. Tutup aplikasi lain (browser, game, dll)\n",
    "2. Kurangi batch_size (16  8 atau 4)\n",
    "3. Kurangi jumlah patches (100  50)\n",
    "4. Monitor GPU usage di Task Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f9c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VISUALISASI HASIL DENOISING\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVISUALISASI HASIL DENOISING\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m visualize_results(trained_model, test_loader, device, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trained_model' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EVALUASI DAN VISUALISASI HASIL\n",
    "# ============================================================================\n",
    "\n",
    "def visualize_results(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualisasi hasil denoising untuk memastikan model bekerja dengan baik\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (noisy, clean) in enumerate(test_loader):\n",
    "            if idx >= num_samples:\n",
    "                break\n",
    "            \n",
    "            noisy = noisy.to(device)\n",
    "            clean = clean.to(device)\n",
    "            \n",
    "            # Denoise\n",
    "            denoised = model(noisy)\n",
    "            \n",
    "            # Ke CPU untuk visualisasi\n",
    "            noisy_img = noisy[0].cpu().permute(1, 2, 0).numpy()\n",
    "            clean_img = clean[0].cpu().permute(1, 2, 0).numpy()\n",
    "            denoised_img = denoised[0].cpu().permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Calculate metrics untuk sample ini\n",
    "            sample_psnr = psnr(denoised[0:1], clean[0:1]).item()\n",
    "            sample_ssim = ssim(denoised[0:1], clean[0:1]).item()\n",
    "            \n",
    "            # Plot\n",
    "            axes[idx, 0].imshow(np.clip(noisy_img, 0, 1))\n",
    "            axes[idx, 0].set_title(f'Noisy Image {idx+1}', fontsize=12)\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            axes[idx, 1].imshow(np.clip(denoised_img, 0, 1))\n",
    "            axes[idx, 1].set_title(f'Denoised (PSNR: {sample_psnr:.2f} dB)', fontsize=12)\n",
    "            axes[idx, 1].axis('off')\n",
    "            \n",
    "            axes[idx, 2].imshow(np.clip(clean_img, 0, 1))\n",
    "            axes[idx, 2].set_title(f'Ground Truth (SSIM: {sample_ssim:.4f})', fontsize=12)\n",
    "            axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('denoising_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\" Results saved: denoising_results.png\")\n",
    "\n",
    "# Uncomment untuk visualisasi hasil:\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VISUALISASI HASIL DENOISING\")\n",
    "print(\"=\" * 70)\n",
    "visualize_results(trained_model, test_loader, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53af604",
   "metadata": {},
   "source": [
    "##  PERBANDINGAN MODEL: best_model.pth vs optimized_halfunet_physical.pth\n",
    "\n",
    "Mari kita evaluasi dan bandingkan kedua model untuk melihat mana yang lebih bagus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c82668bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PERBANDINGAN MODEL\n",
      "======================================================================\n",
      "\n",
      " Mengecek file model...\n",
      "   best_model.pth:  Ada\n",
      "   optimized_halfunet_physical.pth:  Ada\n",
      "\n",
      " Loading models...\n",
      "\n",
      " Model 1 (best_model.pth) loaded successfully!\n",
      "   Metadata:\n",
      "   - Epoch: 3\n",
      "   - Val Loss: 0.044928\n",
      "   - Val PSNR: 24.21 dB\n",
      "   - Val SSIM: 0.5951\n",
      "\n",
      " Model 2 (optimized_halfunet_physical.pth) loaded successfully!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD DAN EVALUASI KEDUA MODEL\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PERBANDINGAN MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Device untuk evaluasi (gunakan CPU untuk konsistensi)\n",
    "eval_device = torch.device('cpu')\n",
    "\n",
    "# Cek apakah file model ada\n",
    "best_model_path = 'best_model.pth'\n",
    "optimized_model_path = 'optimized_halfunet_physical.pth'\n",
    "\n",
    "print(f\"\\n Mengecek file model...\")\n",
    "print(f\"   best_model.pth: {' Ada' if os.path.exists(best_model_path) else ' Tidak ada'}\")\n",
    "print(f\"   optimized_halfunet_physical.pth: {' Ada' if os.path.exists(optimized_model_path) else ' Tidak ada'}\")\n",
    "\n",
    "# Fungsi untuk load model\n",
    "def load_model_for_comparison(model_path, device):\n",
    "    \"\"\"Load model checkpoint untuk evaluasi\"\"\"\n",
    "    model = HalfUNet()\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\" File {model_path} tidak ditemukan!\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # Cek apakah checkpoint adalah dict dengan metadata atau langsung state_dict\n",
    "        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            metadata = {\n",
    "                'epoch': checkpoint.get('epoch', 'N/A'),\n",
    "                'val_loss': checkpoint.get('val_loss', 'N/A'),\n",
    "                'val_psnr': checkpoint.get('val_psnr', 'N/A'),\n",
    "                'val_ssim': checkpoint.get('val_ssim', 'N/A'),\n",
    "            }\n",
    "        else:\n",
    "            # Jika langsung state_dict\n",
    "            model.load_state_dict(checkpoint)\n",
    "            metadata = None\n",
    "        \n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        return model, metadata\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading {model_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "print(f\"\\n Loading models...\")\n",
    "\n",
    "# Load best_model.pth (model hasil training baru)\n",
    "model1, metadata1 = load_model_for_comparison(best_model_path, eval_device)\n",
    "if model1 is not None:\n",
    "    print(f\"\\n Model 1 (best_model.pth) loaded successfully!\")\n",
    "    if metadata1:\n",
    "        print(f\"   Metadata:\")\n",
    "        print(f\"   - Epoch: {metadata1['epoch']}\")\n",
    "        if metadata1['val_loss'] != 'N/A':\n",
    "            print(f\"   - Val Loss: {metadata1['val_loss']:.6f}\")\n",
    "            print(f\"   - Val PSNR: {metadata1['val_psnr']:.2f} dB\")\n",
    "            print(f\"   - Val SSIM: {metadata1['val_ssim']:.4f}\")\n",
    "\n",
    "# Load optimized_halfunet_physical.pth (model yang sudah ada)\n",
    "model2, metadata2 = load_model_for_comparison(optimized_model_path, eval_device)\n",
    "if model2 is not None:\n",
    "    print(f\"\\n Model 2 (optimized_halfunet_physical.pth) loaded successfully!\")\n",
    "    if metadata2:\n",
    "        print(f\"   Metadata:\")\n",
    "        print(f\"   - Epoch: {metadata2['epoch']}\")\n",
    "        if metadata2['val_loss'] != 'N/A':\n",
    "            print(f\"   - Val Loss: {metadata2['val_loss']:.6f}\")\n",
    "            print(f\"   - Val PSNR: {metadata2['val_psnr']:.2f} dB\")\n",
    "            print(f\"   - Val SSIM: {metadata2['val_ssim']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "699d7560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EVALUASI PADA TEST SET\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "EVALUATING: best_model.pth\n",
      "======================================================================\n",
      " Processing 1475 batches...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad35a5038984d43bc92899292e3f6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating best_model.pth:   0%|          | 0/1475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 62\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_loss,\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsnr\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_psnr,\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssim\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_ssim\n\u001b[0;32m     59\u001b[0m     }\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Evaluasi kedua model\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m results1 \u001b[38;5;241m=\u001b[39m evaluate_model_comparison(model1, test_loader, eval_device, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m results2 \u001b[38;5;241m=\u001b[39m evaluate_model_comparison(model2, test_loader, eval_device, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimized_halfunet_physical.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 36\u001b[0m, in \u001b[0;36mevaluate_model_comparison\u001b[1;34m(model, dataloader, device, model_name)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m     35\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 36\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     38\u001b[0m     loss_val \u001b[38;5;241m=\u001b[39m loss_func(outputs, targets)\n\u001b[0;32m     39\u001b[0m     psnr_val \u001b[38;5;241m=\u001b[39m psnr_cpu(outputs, targets)\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 114\u001b[0m, in \u001b[0;36mHalfUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    112\u001b[0m up2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup2(up2)\n\u001b[0;32m    113\u001b[0m up_scaled \u001b[38;5;241m=\u001b[39m x1 \u001b[38;5;241m+\u001b[39m up2 \u001b[38;5;241m+\u001b[39m up3\n\u001b[1;32m--> 114\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_conv(up_scaled)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32md:\\New folder\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1927\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1922\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[1;32m-> 1927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1929\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EVALUASI KEDUA MODEL PADA TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUASI PADA TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Pastikan metrics di CPU\n",
    "ssim_cpu = StructuralSimilarityIndexMeasure(data_range=1.0).to(eval_device)\n",
    "psnr_cpu = PeakSignalNoiseRatio(data_range=1.0).to(eval_device)\n",
    "\n",
    "def evaluate_model_comparison(model, dataloader, device, model_name):\n",
    "    \"\"\"Evaluasi model dengan metrics lengkap\"\"\"\n",
    "    if model is None:\n",
    "        print(f\"\\n {model_name} tidak dapat dievaluasi (model tidak loaded)\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"EVALUATING: {model_name}\")\n",
    "    print('=' * 70)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    loss_func = torch.nn.L1Loss()\n",
    "    \n",
    "    print(f\" Processing {len(dataloader)} batches...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(dataloader, desc=f\"Evaluating {model_name}\")):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss_val = loss_func(outputs, targets)\n",
    "            psnr_val = psnr_cpu(outputs, targets)\n",
    "            ssim_val = ssim_cpu(outputs, targets)\n",
    "            \n",
    "            total_loss += loss_val.item()\n",
    "            total_psnr += psnr_val.item()\n",
    "            total_ssim += ssim_val.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_psnr = total_psnr / len(dataloader)\n",
    "    avg_ssim = total_ssim / len(dataloader)\n",
    "    \n",
    "    print(f\"\\n HASIL {model_name}:\")\n",
    "    print(f\"    Loss (MAE):  {avg_loss:.6f}\")\n",
    "    print(f\"    PSNR:        {avg_psnr:.2f} dB\")\n",
    "    print(f\"    SSIM:        {avg_ssim:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'psnr': avg_psnr,\n",
    "        'ssim': avg_ssim\n",
    "    }\n",
    "\n",
    "# Evaluasi kedua model\n",
    "results1 = evaluate_model_comparison(model1, test_loader, eval_device, \"best_model.pth\")\n",
    "results2 = evaluate_model_comparison(model2, test_loader, eval_device, \"optimized_halfunet_physical.pth\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PERBANDINGAN DAN VISUALISASI HASIL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PERBANDINGAN HASIL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if results1 and results2:\n",
    "    print(\"\\n RINGKASAN PERBANDINGAN:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Header tabel\n",
    "    print(f\"{'Metric':<15} | {'best_model.pth':<20} | {'optimized_halfunet':<20} | {'Winner':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Loss (Lower is better)\n",
    "    loss_winner = \"best_model\" if results1['loss'] < results2['loss'] else \"optimized_halfunet\"\n",
    "    loss_diff = abs(results1['loss'] - results2['loss'])\n",
    "    print(f\"{'Loss (MAE)':<15} | {results1['loss']:<20.6f} | {results2['loss']:<20.6f} | {loss_winner:<15}\")\n",
    "    print(f\"{'  (diff)':<15} | {'':<20} | {'':<20} | {loss_diff:.6f}\")\n",
    "    \n",
    "    # PSNR (Higher is better)\n",
    "    psnr_winner = \"best_model\" if results1['psnr'] > results2['psnr'] else \"optimized_halfunet\"\n",
    "    psnr_diff = abs(results1['psnr'] - results2['psnr'])\n",
    "    print(f\"{'PSNR (dB)':<15} | {results1['psnr']:<20.2f} | {results2['psnr']:<20.2f} | {psnr_winner:<15}\")\n",
    "    print(f\"{'  (diff)':<15} | {'':<20} | {'':<20} | {psnr_diff:.2f} dB\")\n",
    "    \n",
    "    # SSIM (Higher is better)\n",
    "    ssim_winner = \"best_model\" if results1['ssim'] > results2['ssim'] else \"optimized_halfunet\"\n",
    "    ssim_diff = abs(results1['ssim'] - results2['ssim'])\n",
    "    print(f\"{'SSIM':<15} | {results1['ssim']:<20.4f} | {results2['ssim']:<20.4f} | {ssim_winner:<15}\")\n",
    "    print(f\"{'  (diff)':<15} | {'':<20} | {'':<20} | {ssim_diff:.4f}\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Hitung overall winner\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    \n",
    "    if results1['loss'] < results2['loss']:\n",
    "        score1 += 1\n",
    "    else:\n",
    "        score2 += 1\n",
    "    \n",
    "    if results1['psnr'] > results2['psnr']:\n",
    "        score1 += 1\n",
    "    else:\n",
    "        score2 += 1\n",
    "        \n",
    "    if results1['ssim'] > results2['ssim']:\n",
    "        score1 += 1\n",
    "    else:\n",
    "        score2 += 1\n",
    "    \n",
    "    print(f\"\\n OVERALL WINNER:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"   best_model.pth:                 {score1}/3 metrics won\")\n",
    "    print(f\"   optimized_halfunet_physical.pth: {score2}/3 metrics won\")\n",
    "    \n",
    "    if score1 > score2:\n",
    "        print(f\"\\n    best_model.pth LEBIH BAGUS!\")\n",
    "        print(f\"      Model hasil training baru Anda menang di {score1} dari 3 metrics.\")\n",
    "    elif score2 > score1:\n",
    "        print(f\"\\n    optimized_halfunet_physical.pth LEBIH BAGUS!\")\n",
    "        print(f\"      Model yang sudah ada sebelumnya menang di {score2} dari 3 metrics.\")\n",
    "    else:\n",
    "        print(f\"\\n    SERI! Kedua model memiliki performa yang sama.\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Analisis detail\n",
    "    print(f\"\\n ANALISIS:\")\n",
    "    \n",
    "    if psnr_diff < 0.5:\n",
    "        print(f\"    PSNR difference sangat kecil ({psnr_diff:.2f} dB) - kedua model hampir sama\")\n",
    "    elif psnr_diff < 1.0:\n",
    "        print(f\"    PSNR difference kecil ({psnr_diff:.2f} dB) - perbedaan tidak terlalu signifikan\")\n",
    "    else:\n",
    "        print(f\"    PSNR difference cukup besar ({psnr_diff:.2f} dB) - ada perbedaan yang jelas\")\n",
    "    \n",
    "    if ssim_diff < 0.01:\n",
    "        print(f\"    SSIM difference sangat kecil ({ssim_diff:.4f}) - kualitas visual hampir identik\")\n",
    "    elif ssim_diff < 0.05:\n",
    "        print(f\"    SSIM difference kecil ({ssim_diff:.4f}) - kualitas visual sedikit berbeda\")\n",
    "    else:\n",
    "        print(f\"    SSIM difference cukup besar ({ssim_diff:.4f}) - kualitas visual berbeda cukup jelas\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "elif results1 and not results2:\n",
    "    print(\"\\n  Hanya best_model.pth yang berhasil dievaluasi.\")\n",
    "    print(\"    optimized_halfunet_physical.pth tidak ditemukan atau error.\")\n",
    "elif results2 and not results1:\n",
    "    print(\"\\n  Hanya optimized_halfunet_physical.pth yang berhasil dievaluasi.\")\n",
    "    print(\"    best_model.pth tidak ditemukan atau error.\")\n",
    "else:\n",
    "    print(\"\\n Tidak ada model yang berhasil dievaluasi.\")\n",
    "    print(\"   Pastikan file model ada di direktori yang benar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALISASI SIDE-BY-SIDE COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "def visualize_model_comparison(model1, model2, test_loader, device, num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualisasi perbandingan hasil denoising dari kedua model\n",
    "    \"\"\"\n",
    "    if model1 is None or model2 is None:\n",
    "        print(\" Tidak dapat visualisasi - salah satu model tidak loaded\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"VISUALISASI PERBANDINGAN\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model1.to(device)\n",
    "    model2.to(device)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 5, figsize=(20, 4*num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (noisy, clean) in enumerate(test_loader):\n",
    "            if idx >= num_samples:\n",
    "                break\n",
    "            \n",
    "            noisy = noisy.to(device)\n",
    "            clean = clean.to(device)\n",
    "            \n",
    "            # Denoise dengan kedua model\n",
    "            denoised1 = model1(noisy)\n",
    "            denoised2 = model2(noisy)\n",
    "            \n",
    "            # Ke CPU untuk visualisasi\n",
    "            noisy_img = noisy[0].cpu().permute(1, 2, 0).numpy()\n",
    "            clean_img = clean[0].cpu().permute(1, 2, 0).numpy()\n",
    "            denoised1_img = denoised1[0].cpu().permute(1, 2, 0).numpy()\n",
    "            denoised2_img = denoised2[0].cpu().permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Calculate metrics untuk sample ini\n",
    "            psnr1 = psnr_cpu(denoised1[0:1], clean[0:1]).item()\n",
    "            ssim1 = ssim_cpu(denoised1[0:1], clean[0:1]).item()\n",
    "            psnr2 = psnr_cpu(denoised2[0:1], clean[0:1]).item()\n",
    "            ssim2 = ssim_cpu(denoised2[0:1], clean[0:1]).item()\n",
    "            \n",
    "            # Plot\n",
    "            # Column 1: Noisy\n",
    "            axes[idx, 0].imshow(np.clip(noisy_img, 0, 1))\n",
    "            axes[idx, 0].set_title(f'Sample {idx+1}\\nNoisy Image', fontsize=11, fontweight='bold')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            # Column 2: Model 1 (best_model)\n",
    "            axes[idx, 1].imshow(np.clip(denoised1_img, 0, 1))\n",
    "            winner1 = \" \" if psnr1 > psnr2 else \"\"\n",
    "            axes[idx, 1].set_title(f'{winner1}best_model.pth\\nPSNR: {psnr1:.2f} dB\\nSSIM: {ssim1:.4f}', \n",
    "                                   fontsize=10, color='green' if psnr1 > psnr2 else 'black')\n",
    "            axes[idx, 1].axis('off')\n",
    "            \n",
    "            # Column 3: Model 2 (optimized_halfunet)\n",
    "            axes[idx, 2].imshow(np.clip(denoised2_img, 0, 1))\n",
    "            winner2 = \" \" if psnr2 > psnr1 else \"\"\n",
    "            axes[idx, 2].set_title(f'{winner2}optimized_halfunet\\nPSNR: {psnr2:.2f} dB\\nSSIM: {ssim2:.4f}', \n",
    "                                   fontsize=10, color='green' if psnr2 > psnr1 else 'black')\n",
    "            axes[idx, 2].axis('off')\n",
    "            \n",
    "            # Column 4: Ground Truth\n",
    "            axes[idx, 3].imshow(np.clip(clean_img, 0, 1))\n",
    "            axes[idx, 3].set_title(f'Ground Truth\\n(Target)', fontsize=11, fontweight='bold')\n",
    "            axes[idx, 3].axis('off')\n",
    "            \n",
    "            # Column 5: Difference heatmap (antara best_model dan optimized)\n",
    "            diff = np.abs(denoised1_img - denoised2_img)\n",
    "            diff_magnitude = np.mean(diff, axis=2)  # Average across RGB\n",
    "            im = axes[idx, 4].imshow(diff_magnitude, cmap='hot', vmin=0, vmax=0.1)\n",
    "            axes[idx, 4].set_title(f'Difference\\nMean: {np.mean(diff):.4f}', fontsize=10)\n",
    "            axes[idx, 4].axis('off')\n",
    "            plt.colorbar(im, ax=axes[idx, 4], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\n Comparison visualization saved: model_comparison.png\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# Jalankan visualisasi\n",
    "if model1 and model2:\n",
    "    visualize_model_comparison(model1, model2, test_loader, eval_device, num_samples=3)\n",
    "else:\n",
    "    print(\"\\n  Tidak dapat membuat visualisasi - salah satu model tidak loaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
